{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4514aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SnP_daily_update_AMZN.csv\n",
      "        Date   Close    High     Low    Open     Volume\n",
      "0 2010-01-04  6.6950  6.8305  6.6570  6.8125  151998000\n",
      "1 2010-01-05  6.7345  6.7740  6.5905  6.6715  177038000\n",
      "2 2010-01-06  6.6125  6.7365  6.5825  6.7300  143576000\n",
      "3 2010-01-07  6.5000  6.6160  6.4400  6.6005  220604000\n",
      "4 2010-01-08  6.6760  6.6840  6.4515  6.5280  196610000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_path = \"SnP_daily_update.csv\"   # หรือ path ของคุณ\n",
    "raw = pd.read_csv(in_path, low_memory=False)\n",
    "\n",
    "# แถว 0 คือ ticker ของแต่ละคอลัมน์\n",
    "ticker_row = raw.iloc[0]\n",
    "\n",
    "# เก็บคอลัมน์ Date (ชื่อว่า Price) + คอลัมน์ที่ ticker == AMZN\n",
    "keep_cols = [c for c in raw.columns if (c == \"Price\") or (str(ticker_row[c]).upper() == \"AMZN\")]\n",
    "\n",
    "amzn_raw = raw[keep_cols].copy()\n",
    "\n",
    "# ตัด 2 แถวบนสุดออก: (Ticker row) และ (Date label row)\n",
    "amzn = amzn_raw.iloc[2:].copy()\n",
    "\n",
    "# เปลี่ยนชื่อคอลัมน์ให้สะอาด: Price -> Date, Close.31 -> Close (ตัด .xx ออก)\n",
    "rename_map = {\"Price\": \"Date\"}\n",
    "for c in amzn.columns:\n",
    "    if c != \"Price\":\n",
    "        rename_map[c] = c.split(\".\")[0]  # Close.31 -> Close\n",
    "\n",
    "amzn = amzn.rename(columns=rename_map)\n",
    "\n",
    "# แปลงชนิดข้อมูล\n",
    "amzn[\"Date\"] = pd.to_datetime(amzn[\"Date\"], errors=\"coerce\")\n",
    "for c in amzn.columns:\n",
    "    if c != \"Date\":\n",
    "        amzn[c] = pd.to_numeric(amzn[c], errors=\"coerce\")\n",
    "\n",
    "# เรียงตามวันและบันทึก\n",
    "amzn = amzn.sort_values(\"Date\").reset_index(drop=True)\n",
    "amzn.to_csv(\"SnP_daily_update_AMZN.csv\", index=False)\n",
    "\n",
    "print(\"Saved: SnP_daily_update_AMZN.csv\")\n",
    "print(amzn.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e0e8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SnP_daily_update_AMZN_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "in_path = \"SnP_daily_update_AMZN.csv\"   # หรือ path ของคุณ\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "# --- Basic cleaning / types ---\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "for c in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# --- Feature engineering ---\n",
    "\n",
    "# 1) Returns\n",
    "df[\"ret_1\"] = df[\"Close\"].pct_change(1)\n",
    "\n",
    "# 2) Lag returns\n",
    "for k in [2, 3, 4, 5]:\n",
    "    df[f\"ret_{k}\"] = df[\"Close\"].pct_change(k)\n",
    "\n",
    "# 3) Moving average gap (10, 20)\n",
    "df[\"sma_10\"] = df[\"Close\"].rolling(10).mean()\n",
    "df[\"sma_20\"] = df[\"Close\"].rolling(20).mean()\n",
    "df[\"ma_gap_10\"] = (df[\"Close\"] - df[\"sma_10\"]) / df[\"sma_10\"]\n",
    "df[\"ma_gap_20\"] = (df[\"Close\"] - df[\"sma_20\"]) / df[\"sma_20\"]\n",
    "\n",
    "# 4) Intraday range percent\n",
    "df[\"range_pct\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Close\"]\n",
    "\n",
    "# 5) Rolling volatility (std of daily returns)\n",
    "df[\"vol_10\"] = df[\"ret_1\"].rolling(10).std()\n",
    "df[\"vol_20\"] = df[\"ret_1\"].rolling(20).std()\n",
    "\n",
    "# 6) Volume change\n",
    "df[\"vol_chg\"] = df[\"Volume\"].pct_change(1)\n",
    "\n",
    "# 7) Volume relative to average (20)\n",
    "df[\"vol_sma_20\"] = df[\"Volume\"].rolling(20).mean()\n",
    "df[\"vol_ratio_20\"] = df[\"Volume\"] / df[\"vol_sma_20\"]\n",
    "\n",
    "# 8) Close-to-Open return\n",
    "df[\"co_ret\"] = (df[\"Close\"] - df[\"Open\"]) / df[\"Open\"]\n",
    "\n",
    "# 9) Upper/Lower wick (normalized by Close)\n",
    "df[\"upper_wick\"] = (df[\"High\"] - np.maximum(df[\"Open\"], df[\"Close\"])) / df[\"Close\"]\n",
    "df[\"lower_wick\"] = (np.minimum(df[\"Open\"], df[\"Close\"]) - df[\"Low\"]) / df[\"Close\"]\n",
    "\n",
    "# Clean infinities\n",
    "cols_inf = [\"ma_gap_10\", \"ma_gap_20\", \"range_pct\", \"vol_ratio_20\", \"upper_wick\", \"lower_wick\"]\n",
    "df[cols_inf] = df[cols_inf].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"SnP_daily_update_AMZN_features.csv\", index=False)\n",
    "print(\"Saved: SnP_daily_update_AMZN_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0e7940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date       Close  y_ret_t1\n",
      "4044 2026-02-02  242.960007 -0.017863\n",
      "4045 2026-02-03  238.619995 -0.023594\n",
      "4046 2026-02-04  232.990005 -0.044208\n",
      "4047 2026-02-05  222.690002 -0.055548\n",
      "4048 2026-02-06  210.320007       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"SnP_daily_update_AMZN_features.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# 2) Target: next-day return\n",
    "df[\"y_ret_t1\"] = df[\"Close\"].shift(-1) / df[\"Close\"] - 1\n",
    "\n",
    "\n",
    "# แถวสุดท้ายจะไม่มีวันถัดไป -> เป็น NaN (ปกติให้ drop ตอน train)\n",
    "print(df[[\"Date\",\"Close\",\"y_ret_t1\"]].tail())\n",
    "\n",
    "out_path = \"SnP_daily_update_AMZN_features_with_target.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a015963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data used for modeling: (4028, 25)\n",
      "Features used: 15 ['ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5', 'ma_gap_10', 'ma_gap_20', 'range_pct', 'vol_10', 'vol_20', 'vol_chg', 'vol_ratio_20', 'co_ret', 'upper_wick', 'lower_wick']\n",
      "Target: y_ret_t1\n",
      "\n",
      "Fold 1\n",
      " MAE : 0.013963907039339087\n",
      " RMSE: 0.020951408042720807\n",
      " R2  : -0.16558354171099476\n",
      "\n",
      "Fold 2\n",
      " MAE : 0.01183690644808675\n",
      " RMSE: 0.01764176539546164\n",
      " R2  : -0.07379682156729195\n",
      "\n",
      "Fold 3\n",
      " MAE : 0.014923568987767253\n",
      " RMSE: 0.020867118015535615\n",
      " R2  : 0.018073031859547672\n",
      "\n",
      "Fold 4\n",
      " MAE : 0.0180111820673533\n",
      " RMSE: 0.0248311174814252\n",
      " R2  : -0.057356091126401276\n",
      "\n",
      "Fold 5\n",
      " MAE : 0.014685867091944383\n",
      " RMSE: 0.020489822351492524\n",
      " R2  : -0.08040567336743987\n",
      "\n",
      "Average\n",
      " MAE : 0.014684286326898156\n",
      " RMSE: 0.020956246257327157\n",
      " R2  : -0.07181381918251603\n",
      "\n",
      "[Feature Importance] RandomForest (model-based)\n",
      "vol_chg         0.091458\n",
      "vol_ratio_20    0.084983\n",
      "lower_wick      0.081788\n",
      "ma_gap_20       0.077214\n",
      "upper_wick      0.074126\n",
      "range_pct       0.071640\n",
      "co_ret          0.070708\n",
      "ret_1           0.065133\n",
      "ret_2           0.060478\n",
      "ret_5           0.058615\n",
      "dtype: float64\n",
      "\n",
      "[Feature Importance] Permutation (higher = more important)\n",
      "lower_wick      0.000132\n",
      "ma_gap_20       0.000102\n",
      "vol_ratio_20    0.000090\n",
      "vol_chg         0.000065\n",
      "upper_wick      0.000061\n",
      "range_pct       0.000057\n",
      "ret_1           0.000056\n",
      "co_ret          0.000055\n",
      "ret_2           0.000051\n",
      "ret_4           0.000046\n",
      "dtype: float64\n",
      "\n",
      "[Feature Insight] SelectKBest (Top 8 by f_regression)\n",
      "lower_wick    18.422112\n",
      "upper_wick     9.718989\n",
      "ma_gap_20      6.302124\n",
      "ma_gap_10      4.692296\n",
      "ret_4          3.574626\n",
      "ret_3          3.041269\n",
      "ret_5          2.657280\n",
      "co_ret         1.728718\n",
      "dtype: float64\n",
      "\n",
      "[Feature Insight] RFE ranking (1 = selected)\n",
      "ret_1         1\n",
      "ret_4         1\n",
      "ma_gap_20     1\n",
      "ret_5         1\n",
      "range_pct     1\n",
      "co_ret        1\n",
      "lower_wick    1\n",
      "upper_wick    1\n",
      "vol_20        2\n",
      "vol_10        3\n",
      "ret_3         4\n",
      "ret_2         5\n",
      "dtype: int64\n",
      "\n",
      "--- Short report summary (ใช้ในรายงานได้) ---\n",
      "Target ที่ใช้คือ y_ret_t1 (ผลตอบแทนวันพรุ่งนี้) เพราะช่วยให้โมเดลเรียนรู้การเปลี่ยนแปลงได้ดีกว่าระดับราคา.\n",
      "ฟีเจอร์ถูกออกแบบให้เล่าเรื่อง 4 มิติ: trend/momentum, volatility/risk, volume confirmation, และ candle behavior.\n",
      "Feature importance ใช้ 2 มุมมอง: model-based (RF) และ permutation (สลับฟีเจอร์ดูผลกระทบ) เพื่อความน่าเชื่อถือ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# =========================\n",
    "# 1) Load data\n",
    "# =========================\n",
    "path = \"SnP_daily_update_AMZN_features_with_target.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) Storytelling: เป้าหมาย + ฟีเจอร์ที่ใช้\n",
    "# =========================\n",
    "# Target: y_ret_t1 = ผลตอบแทนของวันพรุ่งนี้ (Close_{t+1}/Close_t - 1)\n",
    "# ทำไมใช้ return: โมเดลเรียนรู้ “การเปลี่ยนแปลง” ได้ง่ายกว่า “ระดับราคา” (ราคา trend ยาว / ไม่ stationary)\n",
    "target = \"y_ret_t1\"\n",
    "\n",
    "# ฟีเจอร์ (>=5) แบ่งตามเรื่องเล่า:\n",
    "# A) Momentum/Trend: ret_1..ret_5, ma_gap_10/20 (ราคาอยู่เหนือ/ต่ำกว่าค่าเฉลี่ยแค่ไหน)\n",
    "# B) Volatility/Risk: range_pct, vol_10/20 (วันนี้แกว่งแรงไหม / ช่วงนี้ผันผวนไหม)\n",
    "# C) Volume confirmation: vol_chg, vol_ratio_20 (การยืนยันจากปริมาณซื้อขาย)\n",
    "# D) Candle behavior: co_ret, upper_wick, lower_wick (แรงซื้อ/ขายในแท่งวันนั้น)\n",
    "feature_cols = [\n",
    "    \"ret_1\",\"ret_2\",\"ret_3\",\"ret_4\",\"ret_5\",\n",
    "    \"ma_gap_10\",\"ma_gap_20\",\n",
    "    \"range_pct\",\"vol_10\",\"vol_20\",\n",
    "    \"vol_chg\",\"vol_ratio_20\",\n",
    "    \"co_ret\",\"upper_wick\",\"lower_wick\"\n",
    "]\n",
    "\n",
    "# ลบแถวที่ฟีเจอร์/target ยังเป็น NaN (เกิดจาก rolling เช่น SMA/vol)\n",
    "df_model = df.dropna(subset=feature_cols + [target]).reset_index(drop=True)\n",
    "\n",
    "X = df_model[feature_cols].copy()\n",
    "y = df_model[target].copy()\n",
    "\n",
    "print(\"Data used for modeling:\", df_model.shape)\n",
    "print(\"Features used:\", len(feature_cols), feature_cols)\n",
    "print(\"Target:\", target)\n",
    "\n",
    "# =========================\n",
    "# 3) Train/Test แบบ Time Series (กันข้อมูลรั่ว)\n",
    "# =========================\n",
    "# ใช้ TimeSeriesSplit เพื่อให้ train อยู่ก่อน test เสมอ\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# โมเดลตัวอย่าง: RandomForestRegressor\n",
    "# เหตุผล: จับความสัมพันธ์ไม่เชิงเส้นได้ และมีแนวคิด feature importance แบบ model-based\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ประเมินผลแบบเดินไปข้างหน้า (walk-forward)\n",
    "mae_list, rmse_list, r2_list = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse=np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    print(\" MAE :\", mae)\n",
    "    print(\" RMSE:\", rmse)\n",
    "    print(\" R2  :\", r2)\n",
    "\n",
    "print(\"\\nAverage\")\n",
    "print(\" MAE :\", np.mean(mae_list))\n",
    "print(\" RMSE:\", np.mean(rmse_list))\n",
    "print(\" R2  :\", np.mean(r2_list))\n",
    "\n",
    "# =========================\n",
    "# 4) Feature Importance (ตาม Hint)\n",
    "# =========================\n",
    "# 4.1 Model-based importance (จาก RandomForest)\n",
    "# ช่วยตอบว่า “โมเดลใช้ฟีเจอร์ไหนบ่อย/ช่วยลด error ในการ split มาก”\n",
    "model.fit(X, y)\n",
    "imp_rf = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n[Feature Importance] RandomForest (model-based)\")\n",
    "print(imp_rf.head(10))\n",
    "\n",
    "# 4.2 Permutation importance (แนะนำมาก)\n",
    "# หลักการ: สุ่มสลับค่าฟีเจอร์ทีละตัว แล้วดูว่า score แย่ลงเท่าไหร่\n",
    "# ถ้าแย่ลงมาก = ฟีเจอร์นั้นสำคัญจริง\n",
    "perm = permutation_importance(\n",
    "    model, X, y,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "imp_perm = pd.Series(perm.importances_mean, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n[Feature Importance] Permutation (higher = more important)\")\n",
    "print(imp_perm.head(10))\n",
    "\n",
    "# =========================\n",
    "# 5) Feature Insight (ตัวเลือกเสริม) : SelectKBest + RFE\n",
    "# =========================\n",
    "# 5.1 SelectKBest: ดูความสัมพันธ์เชิงเส้นแบบทีละฟีเจอร์ (เร็ว แต่ไม่เห็น interaction)\n",
    "k = 8\n",
    "skb = SelectKBest(score_func=f_regression, k=k)\n",
    "skb.fit(X, y)\n",
    "skb_scores = pd.Series(skb.scores_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\n[Feature Insight] SelectKBest (Top {k} by f_regression)\")\n",
    "print(skb_scores.head(k))\n",
    "\n",
    "# 5.2 RFE: ค่อยๆ ตัดฟีเจอร์ที่อ่อนออก โดยอิงโมเดลฐาน (LinearRegression)\n",
    "# เหมาะเพื่อให้เห็น “ชุดฟีเจอร์หลัก” แต่ระวังถ้าฟีเจอร์สัมพันธ์กันมาก\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=8)\n",
    "rfe.fit(X, y)\n",
    "rfe_rank = pd.Series(rfe.ranking_, index=feature_cols).sort_values()\n",
    "\n",
    "print(\"\\n[Feature Insight] RFE ranking (1 = selected)\")\n",
    "print(rfe_rank.head(12))\n",
    "\n",
    "# =========================\n",
    "# 6) สรุปสั้นๆเป็นข้อความ (เอาไปใส่รายงานได้)\n",
    "# =========================\n",
    "print(\"\\n--- Short report summary (ใช้ในรายงานได้) ---\")\n",
    "print(\"Target ที่ใช้คือ y_ret_t1 (ผลตอบแทนวันพรุ่งนี้) เพราะช่วยให้โมเดลเรียนรู้การเปลี่ยนแปลงได้ดีกว่าระดับราคา.\")\n",
    "print(\"ฟีเจอร์ถูกออกแบบให้เล่าเรื่อง 4 มิติ: trend/momentum, volatility/risk, volume confirmation, และ candle behavior.\")\n",
    "print(\"Feature importance ใช้ 2 มุมมอง: model-based (RF) และ permutation (สลับฟีเจอร์ดูผลกระทบ) เพื่อความน่าเชื่อถือ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b7c2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "6) Methods (Medium-style) + Results for AMZN (FULL OUTPUT)\n",
      "Dataset: SnP_daily_update_AMZN_features_with_target.csv\n",
      "Usable rows: 4028  | Features: 15  | Target: y_ret_t1\n",
      "Date range: 2010-02-02 to 2026-02-05\n",
      "======================================================\n",
      "\n",
      "6.1 Univariate Selection (SelectKBest with f_regression)\n",
      "Idea: score each feature independently vs target (fast, easy).\n",
      "Limit: doesn't capture interactions between features.\n",
      "\n",
      "Top 8 features (highest f_score):\n",
      "   feature  selectkbest_fscore\n",
      "lower_wick           18.422112\n",
      "upper_wick            9.718989\n",
      " ma_gap_20            6.302124\n",
      " ma_gap_10            4.692296\n",
      "     ret_4            3.574626\n",
      "     ret_3            3.041269\n",
      "     ret_5            2.657280\n",
      "    co_ret            1.728718\n",
      "\n",
      "6.2 Model-based Importance (RandomForest feature_importances_)\n",
      "Idea: features that reduce error in tree splits get higher importance.\n",
      "Limit: can be biased; importance may spread across correlated features.\n",
      "\n",
      "ALL features (sorted):\n",
      "lower_wick      0.106624\n",
      "vol_chg         0.104709\n",
      "ma_gap_20       0.100057\n",
      "vol_ratio_20    0.098948\n",
      "ret_1           0.085976\n",
      "upper_wick      0.083336\n",
      "co_ret          0.070289\n",
      "range_pct       0.066113\n",
      "ret_2           0.046312\n",
      "vol_10          0.045791\n",
      "ret_5           0.043061\n",
      "vol_20          0.040094\n",
      "ret_4           0.037853\n",
      "ma_gap_10       0.036688\n",
      "ret_3           0.034149\n",
      "\n",
      "6.3 RFE (Recursive Feature Elimination) with LinearRegression\n",
      "Idea: repeatedly remove weakest features to keep a core subset.\n",
      "Limit: can be unstable when features are highly correlated.\n",
      "\n",
      "ALL features (sorted by rank):\n",
      "     feature  rfe_rank\n",
      "       ret_1         1\n",
      "       ret_4         1\n",
      "   ma_gap_20         1\n",
      "       ret_5         1\n",
      "   range_pct         1\n",
      "      co_ret         1\n",
      "  lower_wick         1\n",
      "  upper_wick         1\n",
      "      vol_20         2\n",
      "      vol_10         3\n",
      "       ret_3         4\n",
      "       ret_2         5\n",
      "   ma_gap_10         6\n",
      "     vol_chg         7\n",
      "vol_ratio_20         8\n",
      "\n",
      "Selected core features (rank=1):\n",
      "   feature  rfe_rank\n",
      "     ret_1         1\n",
      "     ret_4         1\n",
      " ma_gap_20         1\n",
      "     ret_5         1\n",
      " range_pct         1\n",
      "    co_ret         1\n",
      "lower_wick         1\n",
      "upper_wick         1\n",
      "\n",
      "Exported ONE CSV: AMZN_methods_all_in_one.csv\n",
      "\n",
      "Preview exported table:\n",
      "     feature  selectkbest_fscore  rf_importance  rfe_rank  selectkbest_top8  rfe_selected\n",
      "  lower_wick           18.422112       0.106624         1                 1             1\n",
      "     vol_chg            1.485170       0.104709         7                 0             0\n",
      "   ma_gap_20            6.302124       0.100057         1                 1             1\n",
      "vol_ratio_20            1.418087       0.098948         8                 0             0\n",
      "       ret_1            1.658963       0.085976         1                 0             1\n",
      "  upper_wick            9.718989       0.083336         1                 1             1\n",
      "      co_ret            1.728718       0.070289         1                 1             1\n",
      "   range_pct            0.840657       0.066113         1                 0             1\n",
      "       ret_2            1.576171       0.046312         5                 0             0\n",
      "      vol_10            0.151984       0.045791         3                 0             0\n",
      "       ret_5            2.657280       0.043061         1                 1             1\n",
      "      vol_20            0.475079       0.040094         2                 0             0\n",
      "       ret_4            3.574626       0.037853         1                 1             1\n",
      "   ma_gap_10            4.692296       0.036688         6                 1             0\n",
      "       ret_3            3.041269       0.034149         4                 1             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# =========================\n",
    "# (A) Print settings: ไม่ให้ pandas ตัดบรรทัด/ตัดคอลัมน์\n",
    "# =========================\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# -----------------------------\n",
    "# Load prepared dataset\n",
    "# -----------------------------\n",
    "path = \"SnP_daily_update_AMZN_features_with_target.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "feature_cols = [\n",
    "    \"ret_1\",\"ret_2\",\"ret_3\",\"ret_4\",\"ret_5\",\n",
    "    \"ma_gap_10\",\"ma_gap_20\",\n",
    "    \"range_pct\",\"vol_10\",\"vol_20\",\n",
    "    \"vol_chg\",\"vol_ratio_20\",\n",
    "    \"co_ret\",\"upper_wick\",\"lower_wick\"\n",
    "]\n",
    "target = \"y_ret_t1\"\n",
    "\n",
    "# drop rows that still have NaN (rolling features + last day target)\n",
    "df_model = df.dropna(subset=feature_cols + [target]).reset_index(drop=True)\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target]\n",
    "\n",
    "# -----------------------------\n",
    "# 6.1 SelectKBest (Univariate)\n",
    "# -----------------------------\n",
    "k = 8\n",
    "skb = SelectKBest(score_func=f_regression, k=k)\n",
    "skb.fit(X, y)\n",
    "\n",
    "skb_scores = pd.Series(skb.scores_, index=feature_cols).sort_values(ascending=False)\n",
    "skb_top = skb_scores.head(k).reset_index()\n",
    "skb_top.columns = [\"feature\", \"selectkbest_fscore\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 6.2 RandomForest model-based importance\n",
    "# -----------------------------\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=5\n",
    ")\n",
    "rf.fit(X, y)\n",
    "\n",
    "rf_imp = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "rf_top = rf_imp.reset_index()\n",
    "rf_top.columns = [\"feature\", \"rf_importance\"]  # เอาทุกฟีเจอร์ ไม่ตัด top10\n",
    "\n",
    "# -----------------------------\n",
    "# 6.3 RFE (LinearRegression)\n",
    "# -----------------------------\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=8)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "rfe_rank = pd.Series(rfe.ranking_, index=feature_cols).sort_values()\n",
    "rfe_all = rfe_rank.reset_index()\n",
    "rfe_all.columns = [\"feature\", \"rfe_rank\"]\n",
    "\n",
    "# -----------------------------\n",
    "# (B) แสดงผลแบบไม่ซ่อน: พิมพ์เต็มทุกแถวที่ต้องการ\n",
    "# -----------------------------\n",
    "print(\"======================================================\")\n",
    "print(\"6) Methods (Medium-style) + Results for AMZN (FULL OUTPUT)\")\n",
    "print(\"Dataset:\", path)\n",
    "print(\"Usable rows:\", len(df_model), \" | Features:\", len(feature_cols), \" | Target:\", target)\n",
    "print(\"Date range:\", df_model[\"Date\"].min().date(), \"to\", df_model[\"Date\"].max().date())\n",
    "print(\"======================================================\\n\")\n",
    "\n",
    "print(\"6.1 Univariate Selection (SelectKBest with f_regression)\")\n",
    "print(\"Idea: score each feature independently vs target (fast, easy).\")\n",
    "print(\"Limit: doesn't capture interactions between features.\\n\")\n",
    "print(\"Top 8 features (highest f_score):\")\n",
    "print(skb_top.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"6.2 Model-based Importance (RandomForest feature_importances_)\")\n",
    "print(\"Idea: features that reduce error in tree splits get higher importance.\")\n",
    "print(\"Limit: can be biased; importance may spread across correlated features.\\n\")\n",
    "print(\"ALL features (sorted):\")\n",
    "print(rf_imp.to_string())  # พิมพ์เป็น Series เต็ม\n",
    "print()\n",
    "\n",
    "print(\"6.3 RFE (Recursive Feature Elimination) with LinearRegression\")\n",
    "print(\"Idea: repeatedly remove weakest features to keep a core subset.\")\n",
    "print(\"Limit: can be unstable when features are highly correlated.\\n\")\n",
    "print(\"ALL features (sorted by rank):\")\n",
    "print(rfe_all.to_string(index=False))\n",
    "print()\n",
    "\n",
    "selected = rfe_all[rfe_all[\"rfe_rank\"] == 1].copy()\n",
    "print(\"Selected core features (rank=1):\")\n",
    "print(selected.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# -----------------------------\n",
    "# (C) Export: รวมผลทั้ง 3 วิธีเป็น CSV ไฟล์เดียว\n",
    "# -----------------------------\n",
    "# รวมเป็นตารางเดียว โดยใช้ feature เป็น key\n",
    "final = pd.DataFrame({\"feature\": feature_cols})\n",
    "final[\"selectkbest_fscore\"] = final[\"feature\"].map(skb_scores)      # ได้คะแนนครบทุกฟีเจอร์\n",
    "final[\"rf_importance\"] = final[\"feature\"].map(rf_imp)              # ได้ importance ครบทุกฟีเจอร์\n",
    "final[\"rfe_rank\"] = final[\"feature\"].map(rfe_rank).astype(int)     # rank เป็น int\n",
    "\n",
    "# เพิ่ม flag ให้สไลด์ดูง่าย\n",
    "final[\"selectkbest_top8\"] = final[\"feature\"].isin(skb_top[\"feature\"]).astype(int)\n",
    "final[\"rfe_selected\"] = (final[\"rfe_rank\"] == 1).astype(int)\n",
    "\n",
    "# จัดเรียงให้ดูง่าย (เรียงตาม RF importance ก่อน)\n",
    "final = final.sort_values([\"rf_importance\", \"selectkbest_fscore\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "out_csv = \"AMZN_methods_all_in_one.csv\"\n",
    "final.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Exported ONE CSV:\", out_csv)\n",
    "print(\"\\nPreview exported table:\")\n",
    "print(final.head(15).to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
